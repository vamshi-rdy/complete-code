pipeline {
    agent any

    environment {
        // Define environment variables
        GITHUB_REPO = 'https://github.com/your-org/your-repo.git'
        MAVEN_HOME = tool name: 'Maven 3', type: 'maven'
        SONARQUBE_ENV = 'SonarQube' // Jenkins SonarQube server config name
        S3_BUCKET = 'your-s3-bucket-name'
        DOCKER_REGISTRY = 'your-dockerhub-or-ecr-repo'
        IMAGE_NAME = 'your-app-name'
        AWS_REGION = 'us-east-1'
        EKS_CLUSTER_NAME = 'your-eks-cluster'
        ECR_REGISTRY = 'your-account-id.dkr.ecr.us-east-1.amazonaws.com'
    }

    options {
        skipDefaultCheckout()
        timestamps()
        buildDiscarder(logRotator(numToKeepStr: '10'))
    }

    stages {

        stage('Checkout') {
            steps {
                git credentialsId: 'github-credentials-id', url: "${env.GITHUB_REPO}", branch: 'main'
            }
        }

        stage('Build & Package with Maven') {
            steps {
                withMaven(maven: 'Maven 3') {
                    sh 'mvn clean package -DskipTests'
                }
            }
        }

        stage('SonarQube Analysis') {
            steps {
                withSonarQubeEnv("${env.SONARQUBE_ENV}") {
                    withMaven(maven: 'Maven 3') {
                        sh 'mvn sonar:sonar'
                    }
                }
            }
        }

        stage('Wait for SonarQube Quality Gate') {
            steps {
                timeout(time: 2, unit: 'MINUTES') {
                    script {
                        def qg = waitForQualityGate()
                        if (qg.status != 'OK') {
                            error "Pipeline aborted due to SonarQube quality gate failure: ${qg.status}"
                        }
                    }
                }
            }
        }

        stage('Upload Artifact to S3') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-credentials-id'
                ]]) {
                    script {
                        def artifact = sh(script: "ls target/*.jar | head -1", returnStdout: true).trim()
                        sh "aws s3 cp ${artifact} s3://${S3_BUCKET}/artifacts/ --region ${AWS_REGION}"
                    }
                }
            }
        }

        stage('Build Docker Image') {
            steps {
                script {
                    sh "docker build -t ${IMAGE_NAME}:${BUILD_NUMBER} ."
                }
            }
        }

        stage('Push Docker Image to ECR') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-credentials-id'
                ]]) {
                    script {
                        sh """
                            aws ecr get-login-password --region ${AWS_REGION} | docker login --username AWS --password-stdin ${ECR_REGISTRY}
                            docker tag ${IMAGE_NAME}:${BUILD_NUMBER} ${ECR_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}
                            docker push ${ECR_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}
                        """
                    }
                }
            }
        }

        stage('Scan Docker Image') {
            steps {
                // Using Trivy for image scanning
                sh """
                    trivy image --exit-code 1 --severity CRITICAL,HIGH ${ECR_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER}
                """
            }
        }

        stage('Deploy to EKS') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'aws-credentials-id'
                ]]) {
                    script {
                        sh """
                            aws eks update-kubeconfig --region ${AWS_REGION} --name ${EKS_CLUSTER_NAME}
                            kubectl set image deployment/${IMAGE_NAME} ${IMAGE_NAME}=${ECR_REGISTRY}/${IMAGE_NAME}:${BUILD_NUMBER} --record
                        """
                    }
                }
            }
        }
    }

    post {
        always {
            cleanWs()
        }
        success {
            echo 'Build, analysis, deployment all succeeded.'
        }
        failure {
            echo 'Pipeline failed.'
        }
    }
}

# Using manifest # :
stage('Deploy to EKS') {
    steps {
        withCredentials([[
            $class: 'AmazonWebServicesCredentialsBinding',
            credentialsId: 'aws-credentials-id'
        ]]) {
            script {
                // Optional: update image tag in YAML
                sh "sed -i 's|IMAGE_TAG_PLACEHOLDER|${BUILD_NUMBER}|' k8s/deployment.yaml"

                // Apply manifests
                sh """
                    aws eks update-kubeconfig --region ${AWS_REGION} --name ${EKS_CLUSTER_NAME}
                    kubectl apply -f k8s/
                """
            }
        }
    }
}



 What real projects actually do
Real-world Spring Boot deployments to EKS usually follow one of these patterns:

1. CI/CD Pipeline: kubectl apply -f (Common)
Jenkins (or GitHub Actions/GitLab CI) pipeline includes:

kubectl apply -f k8s/deployment.yaml
Where deployment.yaml includes the full definition of your app: deployment, service, ingress, etc.

You may also dynamically update the image tag in deployment.yaml before applying (e.g., using sed or Helm templating).

2. Helm Charts (Popular for parameterization)
Instead of raw YAML, use Helm for templating:

helm upgrade --install your-app ./chart --set image.tag=${BUILD_NUMBER}
This is more robust for large projects.

3. GitOps (ArgoCD, FluxCD)
CI pipeline just pushes the updated YAML (or Helm values) to a Git repo, and ArgoCD/Flux automatically applies it to the cluster.

This is considered the most production-grade approach today.

üîê Regarding aws eks update-kubeconfig
In CI/CD, you might run it once in the pipeline to configure kubectl context, but in secure environments:

Use a preconfigured Kubernetes context via a service account

Or better, use IAM roles for service accounts (IRSA) with restricted permissions

Avoid using full aws eks update-kubeconfig in pipelines unless needed temporarily

Optional Enhancements
Use Kustomize if you have overlays for dev/staging/prod

Use Helm for reusable charts

Avoid dynamic YAML manipulation with sed ‚Äî instead, template it with Helm or use GitOps


üîê Security Best Practices Implemented
No secrets hardcoded: Uses Jenkins credential IDs (aws-credentials-id, github-credentials-id)

Minimal privilege: Ensure IAM user/role associated with aws-credentials-id has least privilege

Static analysis enforced: SonarQube quality gate enforced with hard fail

Image scanning required: Using Trivy, fails build on critical/high vulnerabilities

Clean workspace: Cleans up at end of pipeline

‚úÖ Tools Assumptions
Jenkins has plugins installed:

Maven Integration

SonarQube Scanner

AWS CLI/SDK

Docker Pipeline

Trivy installed on agent (can use a container agent as well)

Jenkins credentials configured:

GitHub access: github-credentials-id

AWS credentials: aws-credentials-id
